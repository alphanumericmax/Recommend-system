{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "import torch\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import KFold\n",
    "from queue import PriorityQueue\n",
    "\n",
    "\n",
    "\n",
    "path = \"D:/kaggle/MovieLens/\"\n",
    "path2 = 'D:/kaggle/MovieLens/ml-latest-small/'\n",
    "#data = pd.read_csv( path+\"rating.csv\", usecols=[0,1])\n",
    "data = pd.read_csv( path2+\"ratings.csv\", usecols=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100836, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId\n",
       "0       1        1\n",
       "1       1        3\n",
       "2       1        6\n",
       "3       1       47\n",
       "4       1       50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 剔除稀疏的数据\n",
    "temp = data.groupby(['movieId'],as_index=False)['userId'].count().rename(columns={'userId':\"user_count\"})\n",
    "data = data.merge(temp, 'left', 'movieId')\n",
    "data = data[data['user_count'] > 3]\n",
    "temp = data.groupby(['userId'],as_index=False)['movieId'].count().rename(columns={'movieId':\"movie_count\"})\n",
    "data = data.merge(temp, 'left', 'userId')\n",
    "data = data[data['movie_count'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId          610\n",
       "movieId        4180\n",
       "user_count      174\n",
       "movie_count     257\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=8, shuffle=True, random_state=22)\n",
    "\n",
    "for train_index, valid_index in kf.split(data):\n",
    "    train = data.iloc[train_index]\n",
    "    test = data.iloc[valid_index]\n",
    "    user_items = {}\n",
    "    for userid, group in train.groupby(\"userId\"):\n",
    "        user_items[userid] = set( group['movieId'])\n",
    "\n",
    "    item_users = {}\n",
    "    for movieid, group in train.groupby(\"movieId\"):\n",
    "        item_users[movieid] = set( group['userId'])\n",
    "        \n",
    "    test_user_items = {}\n",
    "    for userid, group in test.groupby(\"userId\"):\n",
    "        test_user_items[userid] = set( group['movieId'])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall_Precision(obj, test, topN):\n",
    "    hit = 0\n",
    "    n_recall = 0\n",
    "    n_precision = 0\n",
    "    for user in test.keys():\n",
    "        true = test[user]\n",
    "        rank = obj.recommend(user, length=topN)\n",
    "        rank = {it[0] for it in rank}\n",
    "        hit += len(true & rank)\n",
    "        n_recall += len(true)\n",
    "        n_precision += topN\n",
    "    return hit / n_recall, hit / n_precision\n",
    "\n",
    "\n",
    "def Coverage(obj, test, topN):\n",
    "    recommend_items = set()\n",
    "    all_items = set()\n",
    "    for user in test.keys():\n",
    "        all_items.update( test[user])\n",
    "        rank = obj.recommend(user, length=topN)\n",
    "        rank = {it[0] for it in rank}\n",
    "        recommend_items.update(rank)\n",
    "    return len(recommend_items) / len(all_items)\n",
    "\n",
    "#如果推荐出的物品都很热门，说明推荐的新颖度较低，否则说明推荐结果比较新颖\n",
    "def Popularity(obj, train, topN):\n",
    "    item_popularity = dict()\n",
    "    for user, items in train.items():\n",
    "        for item in items:\n",
    "            item_popularity[item] = item_popularity.get(item, 0) + 1\n",
    "    ret = 0\n",
    "    n = 0\n",
    "    for user in train.keys():\n",
    "        rank = obj.recommend(user, length=topN)\n",
    "        rank = {it[0] for it in rank}\n",
    "        for item in rank:\n",
    "            ret += np.log(1 + item_popularity[item])\n",
    "            n += 1\n",
    "    \n",
    "    return ret / n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFM(object):\n",
    "    def __init__(self, ratio=2, factors=20, epoch=10, alpha=0.1, lambda_=0.01):\n",
    "        self.ratio = ratio                 #正负样例比率，对性能最大影响\n",
    "        self.factors = factors            \n",
    "        self.epoch = epoch                       \n",
    "        self.alpha = alpha                 #梯度下降步长\n",
    "        self.lambda_ = lambda_              #正则化参数\n",
    "        self.istorch = False\n",
    "        \n",
    "    def Random_Select_Negative_Sample(self, hist_items):\n",
    "        ratio = self.ratio\n",
    "        items_pool = self.items_pool\n",
    "        all_sample = dict()\n",
    "        for i in hist_items:\n",
    "            all_sample[i] = 1\n",
    "        n = 0\n",
    "        index = (np.random.rand( len(hist_items) * 3 * ratio) > 0.1)[:len(items_pool)]\n",
    "        for item in items_pool[:len(index)][index]:\n",
    "            if item in all_sample:\n",
    "                continue\n",
    "            all_sample[item] = 0\n",
    "            n += 1\n",
    "            if n >= len(hist_items)*ratio:\n",
    "                break\n",
    "                \n",
    "        return all_sample\n",
    "        \n",
    "    def init_items_pool(self):\n",
    "        item_count = {}\n",
    "        for item, users_set in self.item_users.items():\n",
    "            item_count[item] = len(users_set)\n",
    "            \n",
    "        item_count = sorted(item_count.items(), key=itemgetter(1), reverse=True)\n",
    "        self.items_pool = np.array([i[0] for i in item_count])\n",
    "    \n",
    "    def train(self, user_items, item_users):\n",
    "        self.user_items = user_items\n",
    "        self.item_users = item_users\n",
    "        lambda_ = self.lambda_\n",
    "        alpha   = self.alpha\n",
    "        factors = self.factors\n",
    "        \n",
    "        self.init_items_pool()\n",
    "        usernum = len(user_items)\n",
    "        # 初始化参数\n",
    "        nums = 0\n",
    "        self.P = np.random.randn(usernum+1, factors)\n",
    "        self.Q = {i:np.random.randn(factors) for i in item_users}\n",
    "        for step in range(0, self.epoch):\n",
    "            for user, positive_simple in user_items.items():\n",
    "                nums += 1\n",
    "                if(nums%100==0): print(nums)\n",
    "                all_sample = self.Random_Select_Negative_Sample(positive_simple)\n",
    "                for item, r_ui in all_sample.items():\n",
    "                    e_ui = r_ui - np.dot( self.P[user], self.Q[item])\n",
    "                    self.P[user] += alpha * (e_ui * self.Q[item] - lambda_ * self.P[user])\n",
    "                    self.Q[item] += alpha * (e_ui * self.P[user] - lambda_ * self.Q[item])\n",
    "            alpha *= 0.9\n",
    "            \n",
    "    def train_batch(self, user_items, item_users):\n",
    "        self.istorch = True\n",
    "        self.user_items = user_items\n",
    "        self.item_users = item_users\n",
    "        lambda_ = self.lambda_\n",
    "        alpha   = self.alpha\n",
    "        factors = self.factors\n",
    "        \n",
    "        self.init_items_pool()\n",
    "        usernum = len(user_items)\n",
    "        # 初始化参数\n",
    "        nums = 0\n",
    "        self.P = torch.randn(usernum+1, factors, requires_grad=True)\n",
    "        self.Q = {i:torch.randn(factors, 1, requires_grad=True) for i in item_users}\n",
    "\n",
    "        criterion = torch.nn.BCELoss(reduction='mean')\n",
    "        optimizer = torch.optim.SGD([self.P]+[i for i in self.Q.values()], lr=alpha)\n",
    "\n",
    "        for step in range(0, self.epoch):\n",
    "            for user, positive_simple in user_items.items():\n",
    "                all_sample = self.Random_Select_Negative_Sample(positive_simple)\n",
    "                target = torch.Tensor([r_ui for r_ui in all_sample.values()]).reshape(-1,1)\n",
    "                dot = torch.mm(self.P[user].reshape(-1,factors), torch.cat([self.Q[item] for item in all_sample.keys()], dim=1))\n",
    "                active = torch.sigmoid(dot).reshape(-1,1)\n",
    "                loss = criterion( active, target)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                nums += 1\n",
    "                if(nums%50==0): print(torch.sum(loss))\n",
    "\n",
    "            alpha *= 0.9\n",
    "    \n",
    "    # 加快排序\n",
    "    def recommend_que(self, user, length=10):\n",
    "        rank = []\n",
    "        que = PriorityQueue()\n",
    "        \n",
    "        for item in self.item_users:\n",
    "            if item in user_items[user]:\n",
    "                continue\n",
    "            \n",
    "            if self.istorch == True:\n",
    "                value = torch.dot(self.P[user], self.Q[item].reshape(-1)).item()\n",
    "            else:\n",
    "                value = np.dot(self.P[user], self.Q[item])\n",
    "                \n",
    "            if que.qsize()<length:\n",
    "                que.put((value,item))\n",
    "            else:\n",
    "                last_value, last_item= que.get()\n",
    "                if value>last_value:\n",
    "                    que.put((value,item))\n",
    "                else:\n",
    "                    que.put((last_value, last_item))\n",
    "        while que.qsize()>0:\n",
    "            value,name= que.get()\n",
    "            rank.append((name,value))\n",
    "        return rank\n",
    "    \n",
    "    def recommend(self, user, length=10):\n",
    "        rank = {}\n",
    "        \n",
    "        for item in self.item_users:\n",
    "            if item in user_items[user]:\n",
    "                continue\n",
    "            \n",
    "            if self.istorch == True:\n",
    "                rank[item] = torch.dot(self.P[user], self.Q[item].reshape(-1)).item()\n",
    "            else:\n",
    "                rank[item] = np.dot(self.P[user], self.Q[item])\n",
    "\n",
    "        return sorted(rank.items(), key=itemgetter(1), reverse=True)[0:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8138, grad_fn=<SumBackward0>)\n",
      "tensor(1.8943, grad_fn=<SumBackward0>)\n",
      "tensor(2.0914, grad_fn=<SumBackward0>)\n",
      "tensor(1.6769, grad_fn=<SumBackward0>)\n",
      "tensor(2.1429, grad_fn=<SumBackward0>)\n",
      "tensor(2.6874, grad_fn=<SumBackward0>)\n",
      "tensor(2.3087, grad_fn=<SumBackward0>)\n",
      "tensor(1.7491, grad_fn=<SumBackward0>)\n",
      "tensor(1.6318, grad_fn=<SumBackward0>)\n",
      "tensor(2.6693, grad_fn=<SumBackward0>)\n",
      "tensor(1.5460, grad_fn=<SumBackward0>)\n",
      "tensor(1.9970, grad_fn=<SumBackward0>)\n",
      "tensor(1.8382, grad_fn=<SumBackward0>)\n",
      "tensor(1.7222, grad_fn=<SumBackward0>)\n",
      "tensor(2.3476, grad_fn=<SumBackward0>)\n",
      "tensor(1.5463, grad_fn=<SumBackward0>)\n",
      "tensor(1.8179, grad_fn=<SumBackward0>)\n",
      "tensor(1.9656, grad_fn=<SumBackward0>)\n",
      "tensor(2.1844, grad_fn=<SumBackward0>)\n",
      "tensor(2.0298, grad_fn=<SumBackward0>)\n",
      "tensor(1.7107, grad_fn=<SumBackward0>)\n",
      "tensor(1.7266, grad_fn=<SumBackward0>)\n",
      "tensor(1.1026, grad_fn=<SumBackward0>)\n",
      "tensor(1.8687, grad_fn=<SumBackward0>)\n",
      "tensor(1.3192, grad_fn=<SumBackward0>)\n",
      "tensor(2.0091, grad_fn=<SumBackward0>)\n",
      "tensor(2.7451, grad_fn=<SumBackward0>)\n",
      "tensor(1.2662, grad_fn=<SumBackward0>)\n",
      "tensor(1.4051, grad_fn=<SumBackward0>)\n",
      "tensor(1.8961, grad_fn=<SumBackward0>)\n",
      "tensor(2.2145, grad_fn=<SumBackward0>)\n",
      "tensor(1.8664, grad_fn=<SumBackward0>)\n",
      "tensor(1.6820, grad_fn=<SumBackward0>)\n",
      "tensor(2.0870, grad_fn=<SumBackward0>)\n",
      "tensor(2.0043, grad_fn=<SumBackward0>)\n",
      "tensor(2.2643, grad_fn=<SumBackward0>)\n",
      "tensor(1.7315, grad_fn=<SumBackward0>)\n",
      "tensor(1.4972, grad_fn=<SumBackward0>)\n",
      "tensor(2.4468, grad_fn=<SumBackward0>)\n",
      "tensor(1.9398, grad_fn=<SumBackward0>)\n",
      "tensor(1.4869, grad_fn=<SumBackward0>)\n",
      "tensor(1.7039, grad_fn=<SumBackward0>)\n",
      "tensor(1.0810, grad_fn=<SumBackward0>)\n",
      "tensor(1.9602, grad_fn=<SumBackward0>)\n",
      "tensor(1.8885, grad_fn=<SumBackward0>)\n",
      "tensor(1.6903, grad_fn=<SumBackward0>)\n",
      "tensor(1.9440, grad_fn=<SumBackward0>)\n",
      "tensor(1.3717, grad_fn=<SumBackward0>)\n",
      "tensor(2.1480, grad_fn=<SumBackward0>)\n",
      "tensor(1.1764, grad_fn=<SumBackward0>)\n",
      "tensor(2.0351, grad_fn=<SumBackward0>)\n",
      "tensor(1.6740, grad_fn=<SumBackward0>)\n",
      "tensor(1.6851, grad_fn=<SumBackward0>)\n",
      "tensor(2.4405, grad_fn=<SumBackward0>)\n",
      "tensor(1.6512, grad_fn=<SumBackward0>)\n",
      "tensor(2.0254, grad_fn=<SumBackward0>)\n",
      "tensor(1.6753, grad_fn=<SumBackward0>)\n",
      "tensor(1.6108, grad_fn=<SumBackward0>)\n",
      "tensor(1.8318, grad_fn=<SumBackward0>)\n",
      "tensor(1.8682, grad_fn=<SumBackward0>)\n",
      "tensor(1.3359, grad_fn=<SumBackward0>)\n",
      "tensor(1.7066, grad_fn=<SumBackward0>)\n",
      "tensor(1.7460, grad_fn=<SumBackward0>)\n",
      "tensor(1.8213, grad_fn=<SumBackward0>)\n",
      "tensor(1.5779, grad_fn=<SumBackward0>)\n",
      "tensor(1.6268, grad_fn=<SumBackward0>)\n",
      "tensor(2.1053, grad_fn=<SumBackward0>)\n",
      "tensor(1.8809, grad_fn=<SumBackward0>)\n",
      "tensor(1.5942, grad_fn=<SumBackward0>)\n",
      "tensor(1.5504, grad_fn=<SumBackward0>)\n",
      "tensor(2.3866, grad_fn=<SumBackward0>)\n",
      "tensor(1.4206, grad_fn=<SumBackward0>)\n",
      "tensor(1.9366, grad_fn=<SumBackward0>)\n",
      "tensor(1.7336, grad_fn=<SumBackward0>)\n",
      "tensor(1.4337, grad_fn=<SumBackward0>)\n",
      "tensor(2.2507, grad_fn=<SumBackward0>)\n",
      "tensor(1.2854, grad_fn=<SumBackward0>)\n",
      "tensor(1.7176, grad_fn=<SumBackward0>)\n",
      "tensor(1.9383, grad_fn=<SumBackward0>)\n",
      "tensor(1.7509, grad_fn=<SumBackward0>)\n",
      "tensor(1.7092, grad_fn=<SumBackward0>)\n",
      "tensor(1.5021, grad_fn=<SumBackward0>)\n",
      "tensor(1.6114, grad_fn=<SumBackward0>)\n",
      "tensor(1.0222, grad_fn=<SumBackward0>)\n",
      "tensor(1.7673, grad_fn=<SumBackward0>)\n",
      "tensor(1.1237, grad_fn=<SumBackward0>)\n",
      "tensor(1.8676, grad_fn=<SumBackward0>)\n",
      "tensor(2.1418, grad_fn=<SumBackward0>)\n",
      "tensor(1.0550, grad_fn=<SumBackward0>)\n",
      "tensor(1.2886, grad_fn=<SumBackward0>)\n",
      "tensor(1.8091, grad_fn=<SumBackward0>)\n",
      "tensor(2.1044, grad_fn=<SumBackward0>)\n",
      "tensor(1.8019, grad_fn=<SumBackward0>)\n",
      "tensor(1.5407, grad_fn=<SumBackward0>)\n",
      "tensor(2.0043, grad_fn=<SumBackward0>)\n",
      "tensor(1.8046, grad_fn=<SumBackward0>)\n",
      "tensor(2.1476, grad_fn=<SumBackward0>)\n",
      "tensor(1.6669, grad_fn=<SumBackward0>)\n",
      "tensor(1.3617, grad_fn=<SumBackward0>)\n",
      "tensor(2.0560, grad_fn=<SumBackward0>)\n",
      "tensor(1.6493, grad_fn=<SumBackward0>)\n",
      "tensor(1.4227, grad_fn=<SumBackward0>)\n",
      "tensor(1.6129, grad_fn=<SumBackward0>)\n",
      "tensor(0.9674, grad_fn=<SumBackward0>)\n",
      "tensor(1.8960, grad_fn=<SumBackward0>)\n",
      "tensor(1.7867, grad_fn=<SumBackward0>)\n",
      "tensor(1.4258, grad_fn=<SumBackward0>)\n",
      "tensor(1.8491, grad_fn=<SumBackward0>)\n",
      "tensor(1.2724, grad_fn=<SumBackward0>)\n",
      "tensor(2.1044, grad_fn=<SumBackward0>)\n",
      "tensor(0.9778, grad_fn=<SumBackward0>)\n",
      "tensor(1.7806, grad_fn=<SumBackward0>)\n",
      "tensor(1.5904, grad_fn=<SumBackward0>)\n",
      "tensor(1.6150, grad_fn=<SumBackward0>)\n",
      "tensor(2.2939, grad_fn=<SumBackward0>)\n",
      "tensor(1.6127, grad_fn=<SumBackward0>)\n",
      "tensor(1.6307, grad_fn=<SumBackward0>)\n",
      "tensor(1.5172, grad_fn=<SumBackward0>)\n",
      "tensor(1.4395, grad_fn=<SumBackward0>)\n",
      "tensor(1.7759, grad_fn=<SumBackward0>)\n",
      "tensor(1.7481, grad_fn=<SumBackward0>)\n",
      "tensor(1.2697, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = LFM()\n",
    "model.train_batch( user_items, item_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7115, 17.085277557373047),\n",
       " (1810, 16.6064453125),\n",
       " (2416, 15.810047149658203),\n",
       " (56941, 14.358726501464844),\n",
       " (70, 14.159635543823242),\n",
       " (88405, 14.028036117553711),\n",
       " (725, 13.834428787231445),\n",
       " (3251, 13.271860122680664),\n",
       " (3927, 13.159055709838867),\n",
       " (2950, 13.127809524536133)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.recommend(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2011, 2023, 5481, 5988}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user_items[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
